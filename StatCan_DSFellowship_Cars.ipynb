{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUSUuqerG/zNQsFaNXjXtQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Statistic Canada - Data Science Fellowship Exam"
      ],
      "metadata": {
        "id": "fJZq-ObvubNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dependencies"
      ],
      "metadata": {
        "id": "NnEg2XTd2_wL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IECpYF2BuGp3"
      },
      "outputs": [],
      "source": [
        "# System and IO libraries\n",
        "import os\n",
        "import scipy.io as sio\n",
        "\n",
        "# CV libraries\n",
        "import cv2\n",
        "import PIL\n",
        "\n",
        "# ML libraries\n",
        "import numpy as np\n",
        "import scipy\n",
        "import sklearn\n",
        "import torch\n",
        "import torchvision\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize seed for reproducibility"
      ],
      "metadata": {
        "id": "NNUAEOQ73CnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(1234)"
      ],
      "metadata": {
        "id": "HbpIAF5w3Fnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data collection and preprocessing"
      ],
      "metadata": {
        "id": "pZrCMGqkxlX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use bash commands to download and unzip the data for more convenience and to avoid memory issues when downloading large files using python requests library"
      ],
      "metadata": {
        "id": "rvxq2kOE40Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://ai.stanford.edu/~jkrause/car196/car_ims.tgz\n",
        "!wget http://ai.stanford.edu/~jkrause/car196/cars_annos.mat\n",
        "!tar -zxvf car_ims.tgz;"
      ],
      "metadata": {
        "id": "w4o1vCq6xgft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The label file is a matlab file. A quick google search shows that we can use scipy to load it."
      ],
      "metadata": {
        "id": "m4D9xpL36JTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annos = sio.loadmat(\"cars_annos.mat\", squeeze_me = True)"
      ],
      "metadata": {
        "id": "GCGd5bLGyEYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we will be focusing only on classification and will be creating custom train test splits. We will only need the relative_im_paths and class labels."
      ],
      "metadata": {
        "id": "CSsv6j4huDKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_annotations = {'img_paths': list(cars_annos['annotations']['relative_im_path']),\n",
        "                     'labels': list(cars_annos['annotations']['class'])}"
      ],
      "metadata": {
        "id": "dZzKk3XWyuT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Mask labelled dataset"
      ],
      "metadata": {
        "id": "1D-WN-aLIXDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_masker(dataset_labels, proportion):\n",
        "  ''' \n",
        "  Takes a list of dataset labels (int) and a proportion that needs to \n",
        "  be masked. Returns a dictionary of the orginal list, the masked list \n",
        "  and the masked indices.\n",
        "\n",
        "  Masked labels take the value -1\n",
        "  '''\n",
        "\n",
        "  mask_value = -1\n",
        "  unique_labels = set(dataset_labels)\n",
        "  masked_labels = dataset_labels.copy()\n",
        "\n",
        "  for i in unique_labels:\n",
        "    indices = np.where(np.array(dataset_labels) == i)[0]\n",
        "    mask_indices = random.sample(list(indices), int(len(indices)*proportion))\n",
        "\n",
        "    if len(mask_indices) == len(indices):\n",
        "      raise ValueError('Proportion too high: all classes need to have at ' \n",
        "      'least 1 instance labelled')\n",
        "\n",
        "    for i in mask_indices:\n",
        "      masked_labels[i] = mask_value\n",
        "\n",
        "    masked_indices = list(np.where(np.array(masked_labels) == mask_value)[0])\n",
        "  \n",
        "  return {'original_labels':dataset_labels,\n",
        "          'masked_labels': masked_labels,\n",
        "          'masked_indices': masked_indices}"
      ],
      "metadata": {
        "id": "o22k3a1JAAgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Data cleaning"
      ],
      "metadata": {
        "id": "2UCfjjE1XzwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "nqqP83sj-PS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While it's possible to have 3-channel images that are not RGB like remote sensing images in other spectrums. I will assume that's not the case here and follow the advice in the instructions to simply remove all images that don't have exactly 3 channels."
      ],
      "metadata": {
        "id": "4OpmVRQe-Ocf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_not_rgb(img_path):\n",
        "  '''helper function that checks if image at given path is RGB or not'''\n",
        "  \n",
        "  img = np.array(Image.open(img_path))\n",
        "  if len(img.shape) != 3:\n",
        "    return True\n",
        "\n",
        "  if img.shape[-1] != 3:\n",
        "    return True\n",
        "\n",
        "  return False\n",
        "\n",
        "remove_indices = []\n",
        "\n",
        "for idx, image_path in enumerate(cars_annotations['img_paths']):\n",
        "    if is_not_rgb(image_path):\n",
        "      remove_indices.append(idx)\n",
        "      os.remove(image_path)\n",
        "\n",
        "cars_annotations['img_paths'] = [path for i, path\n",
        "                                 in enumerate(cars_annotations['img_paths'])\n",
        "                                 if i not in remove_indices]\n",
        "\n",
        "cars_annotations['labels'] = [l for i, l\n",
        "                                 in enumerate(cars_annotations['labels'])\n",
        "                                 if i not in remove_indices]"
      ],
      "metadata": {
        "id": "OzBqhggqNBJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Dataset representation"
      ],
      "metadata": {
        "id": "anC5EQeWZNzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: In this step, iteratively loading every image and passing through the model without GPU acceleration turned out to be painfully slow (estimated to be ~1 hour using the time library). I was able to speed this up to 3 minutes by building a dataset class and using Dataloader in pytorch to perform data loading in batches as well as using GPU acceleration."
      ],
      "metadata": {
        "id": "qlmlWXZTAoo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "QRPR6spc1bY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU acceleration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
        "                                  else \"cpu\")"
      ],
      "metadata": {
        "id": "G2xx_Oi8ncx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a custom map-style dataset class is needed by the pytorch dataloader.\n",
        "We will need also need to transform the images as Resnet18 requires the input to be tensors and stacking requires all images to have the same dimension. It is also ideal to normalize images before passing through embedding.\n",
        "\n",
        "Since we are perform embedding before train test split, I will be doing per image normalization (normalizing every image using the image's mean and standard deviation) and not dataset normalization (normalizing every image using the datasets mean and standard deviation) to avoid data leakage."
      ],
      "metadata": {
        "id": "N27eUorMFVZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CarsDataset(Dataset):\n",
        "    \"\"\"Cars dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, annotations, normalize = True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            Annotations(dict): dictionary containing image paths and annotations.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.image_paths = annotations['img_paths']\n",
        "        self.labels = annotations['labels']\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = self.image_paths[idx]\n",
        "        img = cv2.imread(img_name)\n",
        "        img_mean, img_std = cv2.meanStdDev(img)\n",
        "\n",
        "        img_mean_flat = [i[0] for i in img_mean]\n",
        "        img_std_flat = [i[0] for i in img_std]\n",
        "        \n",
        "        transform = transforms.Compose([transforms.ToTensor(), \n",
        "                                        transforms.Resize([224,224])])\n",
        "        image_tensor = transform(img)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        if self.normalize:\n",
        "            self.norm = transforms.Normalize(mean = img_mean_flat,\n",
        "                                              std = img_std_flat)\n",
        "            image_tensor = self.norm(image_tensor)\n",
        "            \n",
        "\n",
        "        sample = (image_tensor, label, idx)\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "LpC31UOJFi0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_dataset = CarsDataset(annotations = cars_annotations)\n",
        "\n",
        "cars_dataloader = torch.utils.data.DataLoader(cars_dataset, batch_size=64,\n",
        "                                              num_workers = 2)"
      ],
      "metadata": {
        "id": "E5FsYcuEJu3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download a pretrained resnet18 model and detaching the last layer to use the model to generate image embeddings. I would typically use resnet50 as it is the industry standard but I understand using the smaller and lighter weight resnet18 for this exercise. Alternatively, Simclr and MOCO are also good models to use for representation learning.\n",
        "\n",
        "It is also usually advised to finetune the model with the custom dataset since the default ImageNet weight don't usually provide good results out of the box. But again this is a luxury given the time constraint."
      ],
      "metadata": {
        "id": "B2BzV1aZ7BP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "model.fc = torch.nn.Identity()\n",
        "model.to(device)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "Oyly8nx9zaKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars_dataset_final = defaultdict(dict)\n",
        "\n",
        "for images, labels, index in cars_dataloader:\n",
        "  with torch.no_grad():\n",
        "    images = images.to(device)\n",
        "    img_embedding = model(images)\n",
        "\n",
        "  for i, idx in enumerate(list(index.numpy())):\n",
        "    img_embedding = img_embedding.cpu()\n",
        "    cars_dataset_final[idx] = {'embedding': img_embedding[i], \n",
        "                        'class_idx': labels[i].item(),\n",
        "                        'labelled': 1} "
      ],
      "metadata": {
        "id": "oOhR13rrLfxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving dataset to disk\n",
        "torch.save(cars_dataset_final, './cars_dataset_final.pth')"
      ],
      "metadata": {
        "id": "iIY5viqPsZk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Mask Cars Dataset"
      ],
      "metadata": {
        "id": "8hdMANgV7Zlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_dataset_final_unmasked = torch.load('./cars_dataset_final.pth')\n",
        "cars_dataset_masked = cars_dataset_final_unmasked.copy()"
      ],
      "metadata": {
        "id": "AcdSUsV-7laX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the function developped in task 1, we mask 60% of the labels to limit ourselves to have only 40% of 'labelled' data for the sake of the exercise."
      ],
      "metadata": {
        "id": "Hscj66EI82Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cars_dataset_labels = [v['class_idx'] for k, v in cars_dataset_final_unmasked.items()]\n",
        "cars_mask = label_masker(cars_dataset_labels, proportion = 0.6)\n",
        "\n",
        "for i in cars_mask['masked_indices']:\n",
        "  cars_dataset_masked[i]['class_idx'] = cars_mask['masked_labels'][i]\n",
        "  cars_dataset_masked[i]['labelled'] = 0"
      ],
      "metadata": {
        "id": "8N7fUcEutNQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: Train/Validation split"
      ],
      "metadata": {
        "id": "G1nZTaHS7mG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(dataset_inputs, dataset_labels, training_proportion):\n",
        "  '''\n",
        "  Takes as input dataset_inputs, dataset_labels, and training_proportion \n",
        "  Returns training_inputs, training_labels, test_inputs, test_labels\n",
        "  '''\n",
        "\n",
        "  dataset_size = len(dataset_inputs)\n",
        "  indices = list(range(dataset_size))\n",
        "\n",
        "  split = int(dataset_size * training_proportion)\n",
        "  random.shuffle(indices)\n",
        "\n",
        "  train_idx, test_idx = indices[:split], indices[split:]\n",
        "\n",
        "  training_inputs = [dataset_inputs[i] for i in train_idx] \n",
        "  training_labels = [dataset_labels[i] for i in train_idx]\n",
        "  \n",
        "  test_inputs = [dataset_inputs[i] for i in test_idx] \n",
        "  test_labels = [dataset_labels[i] for i in test_idx]\n",
        "\n",
        "  return {\n",
        "     'training_inputs': training_inputs,\n",
        "     'training_labels': training_labels,\n",
        "     'test_inputs': test_inputs,\n",
        "     'test_labels': test_labels\n",
        "  }"
      ],
      "metadata": {
        "id": "HCYIFBiS7sbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6: Effect of labelled data on model performance"
      ],
      "metadata": {
        "id": "NYgjOddt72ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model as lm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "yrrgcIrs8Cp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Isolate the 'labelled' (not masked) instances of the cars dataset\n",
        "labelled_cars_dataset = [v for k,v in cars_dataset_masked.items() if v['labelled'] == 1]\n",
        "\n",
        "cars_inputs = [i['embedding'].numpy() for i in labelled_cars_dataset]\n",
        "cars_labels = [i['class_idx'] for i in labelled_cars_dataset]"
      ],
      "metadata": {
        "id": "WXA-Tn_P6tFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming that the client has at least some background knowlege in statistics. we will either show a set of box plots (client has limited background in statistics) or perform hypothesis testing (client has strong background in statistics). Either way, we'd want to demonstrate that the model performance improvement gained from adding more data is statistically significant.\n",
        "\n",
        "To achieve this, we will rerun the experiment 10 times for 2 sets of training proportions (50% and 75%) in the train validation split and evaluate the two population of accuracies for statistical significance. Ideally, we'd want to rerun the experiment at least 30 times for statistical significance, but it is not practical to do this with the time constraints. We can't even not use GPU acceleration to shorten the time as it's not supported by sklearn!\n",
        "\n",
        "Note: I've decided to run SGDClassifier with default parameters like loss = 'hinge' which uses SVMs. If more time was given, the better option is to use log loss and look at the top 5 classification accuracy. Since we have almost 200 balanced classes, top 5 accuracy will be a better measure as it's a more informative way to see how the model is learning. Unfortunately, SGDClassifier with log loss (logistic regression) is 3 times slower than with hinge loss (SVM) and is not practical given the time constraints."
      ],
      "metadata": {
        "id": "x7JICARB51gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluating model with 50% training data\n",
        "classifier50 = lm.SGDClassifier()\n",
        "\n",
        "accuracy_50 = []\n",
        "\n",
        "for i in range(10):\n",
        "  \n",
        "  #setting individual random seed for reproducibility\n",
        "  random.seed(i)\n",
        "\n",
        "  cars_train_test50 = train_test_split(cars_inputs, cars_labels, \n",
        "                                    training_proportion = 0.5)\n",
        "\n",
        "  cars_inputs50_train = cars_train_test50['training_inputs']\n",
        "  cars_labels50_train = cars_train_test50['training_labels']\n",
        "  cars_inputs50_test = cars_train_test50['test_inputs']\n",
        "  cars_labels50_test = cars_train_test50['test_labels']\n",
        "\n",
        "  classifier50.fit(cars_inputs50_train, cars_labels50_train)\n",
        "  y_pred50 = classifier50.predict(cars_inputs50_test)\n",
        "  accuracy_50.append(accuracy_score(cars_labels50_test, y_pred50))"
      ],
      "metadata": {
        "id": "nF26HtYc9fXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and evaluating model with 75% training data\n",
        "classifier75 = lm.SGDClassifier()\n",
        "\n",
        "accuracy_75 = []\n",
        "\n",
        "for i in range(10):\n",
        "  random.seed(i)\n",
        "\n",
        "  cars_train_test75 = train_test_split(cars_inputs, cars_labels, \n",
        "                                    training_proportion = 0.75)\n",
        "\n",
        "  cars_inputs75_train = cars_train_test75['training_inputs']\n",
        "  cars_labels75_train = cars_train_test75['training_labels']\n",
        "  cars_inputs75_test = cars_train_test75['test_inputs']\n",
        "  cars_labels75_test = cars_train_test75['test_labels']\n",
        "\n",
        "  classifier75.fit(cars_inputs75_train, cars_labels75_train)\n",
        "  y_pred75 = classifier75.predict(cars_inputs75_test)\n",
        "  accuracy_75.append(accuracy_score(cars_labels75_test, y_pred75))"
      ],
      "metadata": {
        "id": "Run7iQmG9yXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now analyze the performance difference of increasing 25% training data"
      ],
      "metadata": {
        "id": "WyheXrs-uXpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ttest_ind  "
      ],
      "metadata": {
        "id": "EBJrJgf7ukpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.title('Boxplot of model accuracy with 50% vs 75% training data');\n",
        "plt.xlabel('Model') \n",
        "plt.ylabel('Model Accuracy') \n",
        "ax.boxplot([accuracy_50,accuracy_75], labels = ['50%','75%']);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "s9q-NY_TutiC",
        "outputId": "a38444d2-3b80-4f81-be62-1fd294050f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the boxplot that the mean accuracy of the model trained on 75% of the data is slightly higher than that trained on 50%. However, looking at the distributions, we can not immediately conclude that the difference is significant.\n",
        "\n",
        "Now let's perform a t-test to see if this difference is statistically significant."
      ],
      "metadata": {
        "id": "XxDY1uG9wk6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ttest = ttest_ind(accuracy_75, accuracy_50, alternative = 'greater')"
      ],
      "metadata": {
        "id": "u0C_qhR0w3bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The p-value is {:.2f}\".format(ttest.pvalue))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViuDEhl-x4fi",
        "outputId": "fa343427-fbfc-46f1-bfc1-21b417fec625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The p-value is 0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, the improvement from using 75% vs 50% of training data is not statistically siginificant. This is due to the many issues previously mentioned at not having a large enough sample size (>30), using top-1 accuracy instead of top-5 accuracy. In addition, without finetuning the embedding and tuning the hyperparameters it is very diffcult for the model to learn. Notice that in both cases the accuracies obtain were hardly better than the accuracy of a random classifer (1/197 = 0.005)"
      ],
      "metadata": {
        "id": "HQTP1WUG4bM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7: Active learning"
      ],
      "metadata": {
        "id": "LXTKw0Dw8IMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy"
      ],
      "metadata": {
        "id": "osqHJJqA8OSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict_proba() requires log loss output, we will retrain a new model with log as the loss function using the entire (40%) labelled data"
      ],
      "metadata": {
        "id": "_MFtO_zdVBYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = lm.SGDClassifier(loss= 'log')\n",
        "classifier.fit(cars_inputs, cars_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh6Fo9XFVcKA",
        "outputId": "6544bdd4-1cb3-4d43-f295-0949721acc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(loss='log')"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will now isolate all the unlabelled images"
      ],
      "metadata": {
        "id": "SVRsm09VW6ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unlabelled_cars_dataset = [(k,v['embedding']) for k,v in cars_dataset_masked.items() \n",
        "                                                          if v['labelled'] == 0]\n",
        "\n",
        "unlabelled_cars_indices = [i[0] for i in unlabelled_cars_dataset]\n",
        "unlabelled_cars_inputs = [i[1].numpy() for i in unlabelled_cars_dataset]"
      ],
      "metadata": {
        "id": "2Fcf6wCGW5Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll calculate the entropy of the image embedding and rank them in descending order"
      ],
      "metadata": {
        "id": "05rsBdD2XVuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = classifier.predict_proba(unlabelled_cars_inputs)\n",
        "\n",
        "image_entropy = [(i,entropy(p)) for i,p in zip(unlabelled_cars_indices, y_prob)]\n",
        "image_entropy_rank = sorted(image_entropy, key=lambda i: i[1],\n",
        "    reverse=True)"
      ],
      "metadata": {
        "id": "9p3yrk1BXk1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we take the top K images where the algorithms is most uncertain. Where K is 25% of the length of the orginal dataset (~4000)"
      ],
      "metadata": {
        "id": "DiwuKuMtc7Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = int(0.25*len(cars_dataset_masked.items()))\n",
        "\n",
        "images_to_label_indices = [i[0] for i in image_entropy_rank[:K]]"
      ],
      "metadata": {
        "id": "1Ldf8cc5ZmMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On a side note, looking at the entropy values show that our model performs poorly in general. As the median entropy is high (>3), showing that the model was unsure about most its predictions."
      ],
      "metadata": {
        "id": "1pArT_lZHHHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Median entropy: {:.2f}\".format(image_entropy_rank[int(len(image_entropy_rank)/2)][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-08QP4jHZlR",
        "outputId": "95d89e0b-bc26-4025-be53-8434eec8d560"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median entropy: 3.71\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we construct the final dataset"
      ],
      "metadata": {
        "id": "9zQK7pD1eV8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_cars_dataset_masked = cars_dataset_masked.copy()\n",
        "\n",
        "for i in images_to_label_indices:\n",
        "  final_cars_dataset_masked[i]['class_idx'] = cars_mask['original_labels'][i]\n",
        "  final_cars_dataset_masked[i]['labelled'] = 1\n",
        "\n",
        "# Isolate the 'labelled' (not masked) instances of the cars dataset\n",
        "final_labelled_cars_dataset = [v for k,v in final_cars_dataset_masked.items()\n",
        "                                                       if v['labelled'] == 1]\n",
        "\n",
        "final_cars_inputs = [i['embedding'].numpy() for i in final_labelled_cars_dataset]\n",
        "final_cars_labels = [i['class_idx'] for i in final_labelled_cars_dataset]"
      ],
      "metadata": {
        "id": "BdMeHeeUdiii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 8: Final model training and evaluation"
      ],
      "metadata": {
        "id": "C2a-ybgk8Ms6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the final model, we will split the data using a classic 70/30 split for training and test. Given the time limitation, we won't experiment with new models and do hyper-parameter tuning. I will use the same set up used in Task 6."
      ],
      "metadata": {
        "id": "k-s-lFZlgY_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_final = lm.SGDClassifier(loss = 'log')\n",
        "\n",
        "cars_final_train_test = train_test_split(final_cars_inputs, final_cars_labels, \n",
        "                                                    training_proportion = 0.7)\n",
        "\n",
        "cars_inputs_train_final = cars_final_train_test['training_inputs']\n",
        "cars_labels_train_final = cars_final_train_test['training_labels']\n",
        "cars_inputs_test_final = cars_final_train_test['test_inputs']\n",
        "cars_labels_test_final = cars_final_train_test['test_labels']\n",
        "\n",
        "classifier_final.fit(cars_inputs_train_final, cars_labels_train_final)\n",
        "y_pred_final = classifier_final.predict_proba(cars_inputs_test_final)"
      ],
      "metadata": {
        "id": "BOwom5ejgX5Y"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are only training one model, we can look at more metrics like top 5 accuracy to have a wholistic view of model performace"
      ],
      "metadata": {
        "id": "BOYLAi9OAa_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "kEO4EG8oAjMp"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_1_accuracy = top_k_accuracy_score(cars_labels_test_final, y_pred_final, k = 1)\n",
        "top_5_accuracy = top_k_accuracy_score(cars_labels_test_final, y_pred_final, k = 5)\n",
        "\n",
        "print(\"The top 5 accuracy is {:.3f}\".format(top_5_accuracy))\n",
        "print(\"The top 1 accuracy is {:.3f}\".format(top_1_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fYUzbdP8XAj",
        "outputId": "d66af48d-602e-4919-cea6-199c0f3dd8bf"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 5 accuracy is 0.041\n",
            "The top 1 accuracy is 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model performance is still poor (slightly higher than the random classifier accuracy of 0.005). Although the top 5 accuracy is significantly higher than that of a random classifier, showing that the model was still learning (albeit very slowly). In an a classical ML setting where better performance is the goal, I would definitely focus more on 1) finetuning the embedding model 2) Tuning hyperparameters."
      ],
      "metadata": {
        "id": "jnZzPfIzIUGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the contraints of the exercise, we are unable to determine if labelling more data was the right decision since our model suffers from poor performance due to other issues (no finetuning, no hyperparameter tuning, etc).\n",
        "\n",
        "In general, having more labelled data will always have a positive effect on model performance (it certainly won't make the model perform worse). However, the decision to label more instances can not be decided from just the machine-learning perspective. It depends on a number of factors such as the what the desired model performance is (not simply higher is better), the cost of labelling, etc. A detailed cost-benefit analysis will need to be done together with the client to make the decision of labelling more instances or not."
      ],
      "metadata": {
        "id": "OvFRcjK6BA5_"
      }
    }
  ]
}